---
title: "Robust Federated Learning Against Poisoning Attacks: A GAN-Based Defense Framework."
collection: publications
category: preprint
permalink: /publication/2025-03-26-Robust-Federated-Learning-Against-Poisoning-Attacks
excerpt: ""
date: 2025-03-26
venue: 'Preprint, arXiv:2503.20884'
paperurl: 'https://arxiv.org/pdf/2503.20884'
authors: <b>Usama Zafar</b>, Andr√© Teixeira, and Salman Toor
doi: 
---
### Abstract
Federated Learning (FL) enables collaborative model training across decentralized devices without sharing raw data, but it remains vulnerable to poisoning attacks that compromise model integrity. Existing defenses often rely on external datasets or predefined heuristics (e.g. number of malicious clients), limiting their effectiveness and scalability. To address these limitations, we propose a privacy-preserving defense framework that leverages a Conditional Generative Adversarial Network (cGAN) to generate synthetic data at the server for authenticating client updates, eliminating the need for external datasets. Our framework is scalable, adaptive, and seamlessly integrates into FL workflows. Extensive experiments on benchmark datasets demonstrate its robust performance against a variety of poisoning attacks, achieving high True Positive Rate (TPR) and True Negative Rate (TNR) of malicious and benign clients, respectively, while maintaining model accuracy. The proposed framework offers a practical and effective solution for securing federated learning systems.

<br>

**Links:**
[DOI](https://arxiv.org/abs/2503.20884 "Open Paper"){: .btn-links}
[PDF](https://arxiv.org/pdf/2503.20884 "Download Paper"){: .btn-links}
<!-- [Slides](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10330055 "Download Slides"){: .btn-links} -->
